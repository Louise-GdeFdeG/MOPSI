{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf100
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 MOPSI - Notes du 12/11/2019\
\
- Faire un cas test avec petit nombre de couches et de neurones pour voir si bug (de plot ou autre) dans notre code\
\
- Fonctions \'e0 tester : Une fonction constante, une fonction continue par morceaux et une fonction Cinfini\
\
- Comprendre comment r\'e9gler manuellement les coeffs initiaux du r\'e9seaux (starting guess)(ils sont a priori choisis al\'e9atoirement quand on ne pr\'e9cise rien)\
\
- Regarder si on trouve bien le m\'eame minimiseur (=donn\'e9e des coeffs de toutes les matrices intervenant dans le r\'e9seau) peu importe les valeurs des coeffs initiaux (starting guess)\
\
- Faire une fonction f de r\'e9f\'e9rence qui est l\'92output d\'92un r\'e9seau de neurones et ensuite essayer de l\'92approcher :\
\pard\tx220\tx720\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\li720\fi-720\pardirnatural\partightenfactor0
\ls1\ilvl0\cf0 {\listtext	\uc0\u8226 	}     En utilisant un r\'e9seau qui a m\'eame architecture que le r\'e9seau qui a fourni f\
{\listtext	\uc0\u8226 	}     En utilisant un r\'e9seau qui a une architecture diff\'e9rente\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
- Faire varier, un \'e0 la fois en gardant les autres fix\'e9s, chacun des param\'e8tres de notre r\'e9seau (Profondeur L, Largeur W et starting guess) pour essayer d\'92identifier les effets de ces variations\
\
- Comprendre le fonctionnement de l\'92algorithme de descente de gradient puis de Adam qui a priori s\'92appuie dessus}